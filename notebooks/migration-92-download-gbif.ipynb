{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "499716e2-65b1-4c8e-a525-28c1ee8adddf",
      "metadata": {},
      "source": [
        "# Migration Data Download\n",
        "\n",
        "Get occurrence data from the Global Biodiversity Information Facility\n",
        "(GBIF)\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It: Import packages</div></div><div class=\"callout-body-container callout-body\"><p>In the imports cell, we’ve included some packages that you will need.\n",
        "Add imports for packages that will help you:</p>\n",
        "<ol type=\"1\">\n",
        "<li>Work with reproducible file paths</li>\n",
        "<li>Work with tabular data</li>\n",
        "</ol></div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8710bf77",
      "metadata": {
        "template": "student"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import zipfile\n",
        "from getpass import getpass\n",
        "from glob import glob\n",
        "\n",
        "import pygbif.occurrences as occ\n",
        "import pygbif.species as species\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5a7d036-2a16-4cad-a33b-6f440f336402",
      "metadata": {},
      "source": [
        "For this challenge, you will need to download some data to the computer\n",
        "you’re working on. We suggest using the `earthpy` library we develop to\n",
        "manage your downloads, since it encapsulates many best practices as far\n",
        "as:\n",
        "\n",
        "1.  Where to store your data\n",
        "2.  Dealing with archived data like .zip files\n",
        "3.  Avoiding version control problems\n",
        "4.  Making sure your code works cross-platform\n",
        "5.  Avoiding duplicate downloads\n",
        "\n",
        "If you’re working on one of our assignments through GitHub Classroom, it\n",
        "also lets us build in some handy defaults so that you can see your data\n",
        "files while you work.\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It: Create a project folder</div></div><div class=\"callout-body-container callout-body\"><p>The code below will help you get started with making a project\n",
        "directory</p>\n",
        "<ol type=\"1\">\n",
        "<li>Replace <code>'your-project-directory-name-here'</code> with a\n",
        "<strong>descriptive</strong> name</li>\n",
        "<li>Run the cell</li>\n",
        "<li>The code should have printed out the path to your data files. Check\n",
        "that your data directory exists and has data in it using the terminal or\n",
        "your Finder/File Explorer.</li>\n",
        "</ol></div></div>\n",
        "\n",
        "> **File structure**\n",
        ">\n",
        "> These days, a lot of people find your file by searching for them or\n",
        "> selecting from a `Bookmarks` or `Recents` list. Even if you don’t use\n",
        "> it, your computer also keeps files in a **tree** structure of folders.\n",
        "> Put another way, you can organize and find files by travelling along a\n",
        "> unique **path**, e.g. `My Drive` \\> `Documents` \\>\n",
        "> `My awesome project` \\> `A project file` where each subsequent folder\n",
        "> is **inside** the previous one. This is convenient because all the\n",
        "> files for a project can be in the same place, and both people and\n",
        "> computers can rapidly locate files they want, provided they remember\n",
        "> the path.\n",
        ">\n",
        "> You may notice that when Python prints out a file path like this, the\n",
        "> folder names are **separated** by a `/` or `\\` (depending on your\n",
        "> operating system). This character is called the **file separator**,\n",
        "> and it tells you that the next piece of the path is **inside** the\n",
        "> previous one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "350445b5",
      "metadata": {
        "template": "student"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PosixPath('/workspaces/data/data_download')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import earthpy\n",
        "import os\n",
        "\n",
        "# Create data directory\n",
        "#project = earthpy.Project(\n",
        "    #dirname='data_download',)\n",
        "\n",
        "project = earthpy.Project(dirname='/workspaces/data/data_download')\n",
        "\n",
        "\n",
        "# Display the project directory\n",
        "project.project_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcacff13-2eda-4474-ae4d-8985a615a148",
      "metadata": {},
      "source": [
        "### STEP 1: Register and log in to GBIF\n",
        "\n",
        "You will need a [GBIF account](https://www.gbif.org/) to complete this\n",
        "challenge. You can use your GitHub account to authenticate with GBIF.\n",
        "Then, run the following code to enter your credentials for the rest of\n",
        "your session.\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-error\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div></div><div class=\"callout-body-container callout-body\"><p>This code is <strong>interactive</strong>, meaning that it will\n",
        "<strong>ask you for a response</strong>! The prompt can sometimes be\n",
        "hard to see if you are using VSCode – it appears at the\n",
        "<strong>top</strong> of your editor window.</p></div></div>\n",
        "\n",
        "> **Tip**\n",
        ">\n",
        "> If you need to save credentials across multiple sessions, you can\n",
        "> consider loading them in from a file like a `.env`…but make sure to\n",
        "> add it to .gitignore so you don’t commit your credentials to your\n",
        "> repository!\n",
        "\n",
        "> **Warning**\n",
        ">\n",
        "> Your email address **must** match the email you used to sign up for\n",
        "> GBIF!\n",
        "\n",
        "> **Tip**\n",
        ">\n",
        "> If you accidentally enter your credentials wrong, you can set\n",
        "> `reset=True` instead of `reset=False`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fe449f8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "####--------------------------####\n",
        "#### DO NOT MODIFY THIS CODE! ####\n",
        "####--------------------------####\n",
        "# This code ASKS for your credentials \n",
        "# and saves it for the rest of the session.\n",
        "# NEVER put your credentials into your code!!!!\n",
        "\n",
        "# GBIF needs a username, password, and email \n",
        "# All 3 need to match the account\n",
        "reset = True\n",
        "\n",
        "\n",
        "# Request and store username\n",
        "if (not ('GBIF_USER'  in os.environ)) or reset:\n",
        "    os.environ['GBIF_USER'] = input('GBIF username:')\n",
        "\n",
        "# Securely request and store password\n",
        "if (not ('GBIF_PWD'  in os.environ)) or reset:\n",
        "    os.environ['GBIF_PWD'] = getpass('GBIF password:')\n",
        "    \n",
        "# Request and store account email address\n",
        "if (not ('GBIF_EMAIL'  in os.environ)) or reset:\n",
        "    os.environ['GBIF_EMAIL'] = input('GBIF email:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "70c74283",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('kai_skowlund', '#Ricothedog465', 'kask8596@colorado.edu')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.environ['GBIF_USER'], os.environ['GBIF_PWD'], os.environ['GBIF_EMAIL']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3586b2e0-3968-44a4-bb25-22d516ddd5d1",
      "metadata": {},
      "source": [
        "### STEP 2: Get the taxon key from GBIF\n",
        "\n",
        "One of the tricky parts about getting occurrence data from GBIF is that\n",
        "species often have multiple names in different contexts. Luckily, GBIF\n",
        "also provides a Name Backbone service that will translate scientific and\n",
        "colloquial names into unique identifiers. GBIF calls these identifiers\n",
        "**taxon keys**.\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It</div></div><div class=\"callout-body-container callout-body\"><ol type=\"1\">\n",
        "<li>Put the species name, <code>{python}  scientific_name</code>, into\n",
        "the correct location in the code below.</li>\n",
        "<li>Examine the object you get back from the species query. What part of\n",
        "it do you think might be the taxon key?</li>\n",
        "<li>Extract and save the taxon key</li>\n",
        "</ol></div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6d361296",
      "metadata": {
        "template": "student"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'usageKey': 2438662, 'scientificName': 'Microtus gerbei (Gerbe, 1879)', 'canonicalName': 'Microtus gerbei', 'rank': 'SPECIES', 'status': 'ACCEPTED', 'confidence': 99, 'matchType': 'EXACT', 'kingdom': 'Animalia', 'phylum': 'Chordata', 'order': 'Rodentia', 'family': 'Cricetidae', 'genus': 'Microtus', 'species': 'Microtus gerbei', 'kingdomKey': 1, 'phylumKey': 44, 'classKey': 359, 'orderKey': 1459, 'familyKey': 3240723, 'genusKey': 2438591, 'speciesKey': 2438662, 'class': 'Mammalia'}\n"
          ]
        }
      ],
      "source": [
        "from pygbif import species\n",
        "scientific_name = \"Microtus gerbei\"\n",
        "backbone = species.name_backbone(name=scientific_name)\n",
        "print(backbone)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38592c73",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f452db5f-305a-456d-a9e3-2b114530d129",
      "metadata": {},
      "source": [
        "### STEP 3: Download data from GBIF\n",
        "\n",
        "Downloading GBIF data is a multi-step process. However, we’ve provided\n",
        "you with a chunk of code that handles the API communications and caches\n",
        "the download. You’ll still need to customize your search.\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It: Submit a request to GBIF</div></div><div class=\"callout-body-container callout-body\"><ol type=\"1\">\n",
        "<li><p>Replace <code>csv_file_pattern</code> with a string that will\n",
        "match <strong>any</strong> <code>.csv</code> file when used in the\n",
        "<code>.rglob()</code> method. HINT: the character <code>*</code>\n",
        "represents any number of any values except the file separator\n",
        "(e.g. <code>/</code> on UNIX systems)</p></li>\n",
        "<li><p>Add parameters to the GBIF download function,\n",
        "<code>occ.download()</code> to limit your query to:</p>\n",
        "<ul>\n",
        "<li>observations of <span data-__quarto_custom=\"true\"\n",
        "data-__quarto_custom_type=\"Shortcode\"\n",
        "data-__quarto_custom_context=\"Inline\"\n",
        "data-__quarto_custom_id=\"8\"></span></li>\n",
        "<li>from <span data-__quarto_custom=\"true\"\n",
        "data-__quarto_custom_type=\"Shortcode\"\n",
        "data-__quarto_custom_context=\"Inline\"\n",
        "data-__quarto_custom_id=\"9\"></span></li>\n",
        "<li>with spatial coordinates.</li>\n",
        "</ul></li>\n",
        "<li><p>Then, run the download. <strong>This can take a few\n",
        "minutes</strong>. You can check your downloads by logging on to the <a\n",
        "href=\"https://www.gbif.org/user/download\">GBIF website</a>.</p></li>\n",
        "</ol></div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1e806449",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kai_skowlund\n",
            "kask8596@colorado.edu\n"
          ]
        }
      ],
      "source": [
        "print(os.environ.get('GBIF_USER'))\n",
        "print(os.environ.get('GBIF_EMAIL'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "35cf4589",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PosixPath('/workspaces/data/data_download/gbi_data/0055584-251009101135966.csv')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Only download once\n",
        "\n",
        "taxon_key = 2438662\n",
        "\n",
        "if not any(project.project_dir.rglob('*.csv')):\n",
        "    # Only submit one request\n",
        "    if not 'GBIF_DOWNLOAD_KEY' in os.environ:\n",
        "        # Submit query to GBIF\n",
        "        gbif_query = occ.download(\n",
        "            [\n",
        "                f'taxonKey = {taxon_key}',\n",
        "                'hasCoordinate = true',\n",
        "                'year >= 2000',\n",
        "            ],\n",
        "            user=os.environ['GBIF_USER'].strip(),\n",
        "            pwd=os.environ['GBIF_PWD'].strip(),\n",
        "            email=os.environ['GBIF_EMAIL'].strip()\n",
        "        )\n",
        "        # Take first result\n",
        "        os.environ['GBIF_DOWNLOAD_KEY'] = gbif_query[0]\n",
        "\n",
        "    # Wait for the download to build\n",
        "    dld_key = os.environ['GBIF_DOWNLOAD_KEY']\n",
        "    wait = occ.download_meta(dld_key)['status']\n",
        "    while not wait == 'SUCCEEDED':\n",
        "        time.sleep(5)\n",
        "        wait = occ.download_meta(dld_key)['status']\n",
        "\n",
        "    # Download GBIF data\n",
        "    dld_info = occ.download_get(\n",
        "        os.environ['GBIF_DOWNLOAD_KEY'],\n",
        "        path=project.project_dir\n",
        "    )\n",
        "    dld_path = dld_info['path']\n",
        "\n",
        "    # Unzip GBIF data\n",
        "    with zipfile.ZipFile(dld_path) as dld_zip:\n",
        "        dld_zip.extractall(path=project.project_dir)\n",
        "\n",
        "    # Clean up the .zip file\n",
        "    os.remove(dld_path)\n",
        "\n",
        "# ✅ Corrected CSV search pattern\n",
        "original_gbif_path = next(project.project_dir.rglob('*.csv'))\n",
        "original_gbif_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52cb7205-ef67-48e0-a318-7fba28465682",
      "metadata": {},
      "source": [
        "You might notice that the GBIF data filename isn’t very\n",
        "**descriptive**…at this point, you may want to clean up your data\n",
        "directory so that you know what the file is later on!\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It</div></div><div class=\"callout-body-container callout-body\"><ol type=\"1\">\n",
        "<li>Replace ‘your-gbif-filename’ with a <strong>descriptive</strong>\n",
        "name.</li>\n",
        "<li>Run the cell</li>\n",
        "<li>Check your data folder. Is it organized the way you want?</li>\n",
        "</ol></div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "574f4447",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'GBIF_DOWNLOAD_KEY'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dld_info = occ.download_get(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGBIF_DOWNLOAD_KEY\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, path=project.project_dir)\n\u001b[32m      2\u001b[39m dld_path = dld_info[\u001b[33m'\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(dld_path)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:679\u001b[39m, in \u001b[36m__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'GBIF_DOWNLOAD_KEY'"
          ]
        }
      ],
      "source": [
        "dld_info = occ.download_get(os.environ['GBIF_DOWNLOAD_KEY'], path=project.project_dir)\n",
        "dld_path = dld_info['path']\n",
        "print(dld_path)\n",
        "\n",
        "import zipfile\n",
        "extract_dir = project.project_dir / \"gbi_data\"  # create a descriptive folder\n",
        "extract_dir.mkdir(exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(dld_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(list(extract_dir.glob('*')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d48139",
      "metadata": {
        "template": "student"
      },
      "outputs": [
        {
          "ename": "Error",
          "evalue": "Cannot move a directory '/workspaces/data/data_download' into itself '/workspaces/data/data_download/gbi_data'.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/shutil.py:825\u001b[39m, in \u001b[36mmove\u001b[39m\u001b[34m(src, dst, copy_function)\u001b[39m\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
            "\u001b[31mOSError\u001b[39m: [Errno 22] Invalid argument: '/workspaces/data/data_download' -> '/workspaces/data/data_download/gbi_data/data_download'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mError\u001b[39m                                     Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m gbif_path = project.project_dir / \u001b[33m'\u001b[39m\u001b[33mgbi_data\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Move file to descriptive path\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/workspaces/data/data_download\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgbif_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/shutil.py:833\u001b[39m, in \u001b[36mmove\u001b[39m\u001b[34m(src, dst, copy_function)\u001b[39m\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m os.path.isdir(src):\n\u001b[32m    832\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _destinsrc(src, dst):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[33m\"\u001b[39m\u001b[33mCannot move a directory \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m into itself\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    834\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % (src, dst))\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (_is_immutable(src)\n\u001b[32m    836\u001b[39m             \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m os.access(src, os.W_OK) \u001b[38;5;129;01mand\u001b[39;00m os.listdir(src)\n\u001b[32m    837\u001b[39m                 \u001b[38;5;129;01mand\u001b[39;00m sys.platform == \u001b[33m'\u001b[39m\u001b[33mdarwin\u001b[39m\u001b[33m'\u001b[39m)):\n\u001b[32m    838\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mPermissionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot move the non-empty directory \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    839\u001b[39m                               \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: Lacking write permission to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    840\u001b[39m                               % (src, src))\n",
            "\u001b[31mError\u001b[39m: Cannot move a directory '/workspaces/data/data_download' into itself '/workspaces/data/data_download/gbi_data'."
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Give the download a descriptive name\n",
        "gbif_path = project.project_dir / 'gbi_data'\n",
        "# Move file to descriptive path\n",
        "shutil.move('/workspaces/data/data_download', gbif_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d154d4c1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "47037264-65fc-4fb3-b43a-c53bcd4ba968",
      "metadata": {},
      "source": [
        "### STEP 4: Load the GBIF data into Python\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It: Load GBIF data</div></div><div class=\"callout-body-container callout-body\"><p>Just like you did when wrangling your data from the data subset,\n",
        "you’ll need to load your GBIF data and convert it to a GeoDataFrame.</p></div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "042cdc1e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       gbifID                            datasetKey  \\\n",
            "0  4909017858  50c9509d-22c7-4a22-a47d-8c48425ef4a7   \n",
            "1  4907997343  50c9509d-22c7-4a22-a47d-8c48425ef4a7   \n",
            "2  4907993789  50c9509d-22c7-4a22-a47d-8c48425ef4a7   \n",
            "3  4588626922  23e8afeb-7655-421d-a4a5-ee562e88a475   \n",
            "4  4588454633  23e8afeb-7655-421d-a4a5-ee562e88a475   \n",
            "\n",
            "                                        occurrenceID   kingdom    phylum  \\\n",
            "0  https://www.inaturalist.org/observations/21827...  Animalia  Chordata   \n",
            "1  https://www.inaturalist.org/observations/21951...  Animalia  Chordata   \n",
            "2  https://www.inaturalist.org/observations/21906...  Animalia  Chordata   \n",
            "3               78c2da30-0d25-45ff-80c5-c44e71a798c8  Animalia  Chordata   \n",
            "4               77cd6a41-7ef5-4664-b2c8-9414b5e0a139  Animalia  Chordata   \n",
            "\n",
            "      class     order      family     genus          species  ...  \\\n",
            "0  Mammalia  Rodentia  Cricetidae  Microtus  Microtus gerbei  ...   \n",
            "1  Mammalia  Rodentia  Cricetidae  Microtus  Microtus gerbei  ...   \n",
            "2  Mammalia  Rodentia  Cricetidae  Microtus  Microtus gerbei  ...   \n",
            "3  Mammalia  Rodentia  Cricetidae  Microtus  Microtus gerbei  ...   \n",
            "4  Mammalia  Rodentia  Cricetidae  Microtus  Microtus gerbei  ...   \n",
            "\n",
            "       identifiedBy       dateIdentified       license      rightsHolder  \\\n",
            "0  Dr. Sven Gippner  2024-06-19T10:09:53  CC_BY_NC_4_0  Dr. Sven Gippner   \n",
            "1  Dr. Sven Gippner  2024-06-19T10:32:00  CC_BY_NC_4_0  Dr. Sven Gippner   \n",
            "2  Dr. Sven Gippner  2024-06-19T10:25:01  CC_BY_NC_4_0  Dr. Sven Gippner   \n",
            "3               NaN                  NaN     CC_BY_4_0               NaN   \n",
            "4               NaN                  NaN     CC_BY_4_0               NaN   \n",
            "\n",
            "                                      recordedBy typeStatus  \\\n",
            "0                               Dr. Sven Gippner        NaN   \n",
            "1                               Dr. Sven Gippner        NaN   \n",
            "2                               Dr. Sven Gippner        NaN   \n",
            "3  Catil Jean-Michel (Nature En Occitanie (NEO))        NaN   \n",
            "4  Catil Jean-Michel (Nature En Occitanie (NEO))        NaN   \n",
            "\n",
            "  establishmentMeans           lastInterpreted   mediaType  \\\n",
            "0                NaN  2025-10-20T20:13:48.105Z  StillImage   \n",
            "1                NaN  2025-10-20T21:24:50.619Z  StillImage   \n",
            "2                NaN  2025-10-20T20:15:22.655Z  StillImage   \n",
            "3                NaN  2025-10-07T22:01:15.560Z         NaN   \n",
            "4                NaN  2025-10-07T22:01:14.607Z         NaN   \n",
            "\n",
            "                                               issue  \n",
            "0  COORDINATE_ROUNDED;CONTINENT_DERIVED_FROM_COOR...  \n",
            "1  COORDINATE_ROUNDED;CONTINENT_DERIVED_FROM_COOR...  \n",
            "2  COORDINATE_ROUNDED;CONTINENT_DERIVED_FROM_COOR...  \n",
            "3  FOOTPRINT_WKT_MISMATCH;CONTINENT_DERIVED_FROM_...  \n",
            "4  FOOTPRINT_WKT_MISMATCH;CONTINENT_DERIVED_FROM_...  \n",
            "\n",
            "[5 rows x 50 columns]\n",
            "Index(['gbifID', 'datasetKey', 'occurrenceID', 'kingdom', 'phylum', 'class',\n",
            "       'order', 'family', 'genus', 'species', 'infraspecificEpithet',\n",
            "       'taxonRank', 'scientificName', 'verbatimScientificName',\n",
            "       'verbatimScientificNameAuthorship', 'countryCode', 'locality',\n",
            "       'stateProvince', 'occurrenceStatus', 'individualCount',\n",
            "       'publishingOrgKey', 'decimalLatitude', 'decimalLongitude',\n",
            "       'coordinateUncertaintyInMeters', 'coordinatePrecision', 'elevation',\n",
            "       'elevationAccuracy', 'depth', 'depthAccuracy', 'eventDate', 'day',\n",
            "       'month', 'year', 'taxonKey', 'speciesKey', 'basisOfRecord',\n",
            "       'institutionCode', 'collectionCode', 'catalogNumber', 'recordNumber',\n",
            "       'identifiedBy', 'dateIdentified', 'license', 'rightsHolder',\n",
            "       'recordedBy', 'typeStatus', 'establishmentMeans', 'lastInterpreted',\n",
            "       'mediaType', 'issue'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = '/workspaces/data/data_download/gbi_data/0055584-251009101135966.csv'\n",
        "\n",
        "# Try tab delimiter\n",
        "df2 = pd.read_csv(csv_path, sep='\\t', low_memory=False)\n",
        "\n",
        "print(df2.head())\n",
        "print(df2.columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c54ae8e2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-4.17    42.38     3.32788 47.24778]\n",
            "       gbifID                            datasetKey  \\\n",
            "0  4909017858  50c9509d-22c7-4a22-a47d-8c48425ef4a7   \n",
            "1  4907997343  50c9509d-22c7-4a22-a47d-8c48425ef4a7   \n",
            "2  4907993789  50c9509d-22c7-4a22-a47d-8c48425ef4a7   \n",
            "3  4588626922  23e8afeb-7655-421d-a4a5-ee562e88a475   \n",
            "4  4588454633  23e8afeb-7655-421d-a4a5-ee562e88a475   \n",
            "\n",
            "                                        occurrenceID   kingdom    phylum  \\\n",
            "0  https://www.inaturalist.org/observations/21827...  Animalia  Chordata   \n",
            "1  https://www.inaturalist.org/observations/21951...  Animalia  Chordata   \n",
            "2  https://www.inaturalist.org/observations/21906...  Animalia  Chordata   \n",
            "3               78c2da30-0d25-45ff-80c5-c44e71a798c8  Animalia  Chordata   \n",
            "4               77cd6a41-7ef5-4664-b2c8-9414b5e0a139  Animalia  Chordata   \n",
            "\n",
            "      class     order      family     genus          species  ...  \\\n",
            "0  Mammalia  Rodentia  Cricetidae  Microtus  Microtus gerbei  ...   \n",
            "1  Mammalia  Rodentia  Cricetidae  Microtus  Microtus gerbei  ...   \n",
            "2  Mammalia  Rodentia  Cricetidae  Microtus  Microtus gerbei  ...   \n",
            "3  Mammalia  Rodentia  Cricetidae  Microtus  Microtus gerbei  ...   \n",
            "4  Mammalia  Rodentia  Cricetidae  Microtus  Microtus gerbei  ...   \n",
            "\n",
            "        dateIdentified       license      rightsHolder  \\\n",
            "0  2024-06-19T10:09:53  CC_BY_NC_4_0  Dr. Sven Gippner   \n",
            "1  2024-06-19T10:32:00  CC_BY_NC_4_0  Dr. Sven Gippner   \n",
            "2  2024-06-19T10:25:01  CC_BY_NC_4_0  Dr. Sven Gippner   \n",
            "3                  NaN     CC_BY_4_0               NaN   \n",
            "4                  NaN     CC_BY_4_0               NaN   \n",
            "\n",
            "                                      recordedBy typeStatus  \\\n",
            "0                               Dr. Sven Gippner        NaN   \n",
            "1                               Dr. Sven Gippner        NaN   \n",
            "2                               Dr. Sven Gippner        NaN   \n",
            "3  Catil Jean-Michel (Nature En Occitanie (NEO))        NaN   \n",
            "4  Catil Jean-Michel (Nature En Occitanie (NEO))        NaN   \n",
            "\n",
            "  establishmentMeans           lastInterpreted   mediaType  \\\n",
            "0                NaN  2025-10-20T20:13:48.105Z  StillImage   \n",
            "1                NaN  2025-10-20T21:24:50.619Z  StillImage   \n",
            "2                NaN  2025-10-20T20:15:22.655Z  StillImage   \n",
            "3                NaN  2025-10-07T22:01:15.560Z         NaN   \n",
            "4                NaN  2025-10-07T22:01:14.607Z         NaN   \n",
            "\n",
            "                                               issue  \\\n",
            "0  COORDINATE_ROUNDED;CONTINENT_DERIVED_FROM_COOR...   \n",
            "1  COORDINATE_ROUNDED;CONTINENT_DERIVED_FROM_COOR...   \n",
            "2  COORDINATE_ROUNDED;CONTINENT_DERIVED_FROM_COOR...   \n",
            "3  FOOTPRINT_WKT_MISMATCH;CONTINENT_DERIVED_FROM_...   \n",
            "4  FOOTPRINT_WKT_MISMATCH;CONTINENT_DERIVED_FROM_...   \n",
            "\n",
            "                    geometry  \n",
            "0  POINT (-0.35588 42.77899)  \n",
            "1  POINT (-0.41895 42.80429)  \n",
            "2  POINT (-0.35854 42.77446)  \n",
            "3   POINT (0.37661 43.52802)  \n",
            "4   POINT (0.32365 43.39891)  \n",
            "\n",
            "[5 rows x 51 columns]\n"
          ]
        }
      ],
      "source": [
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "\n",
        "gdf2 = gpd.GeoDataFrame(\n",
        "    df2,\n",
        "    geometry=[Point(xy) for xy in zip(df2.decimalLongitude, df2.decimalLatitude)],\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "print(gdf2.total_bounds)\n",
        "print(gdf2.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f9e629b",
      "metadata": {
        "template": "student"
      },
      "outputs": [
        {
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 2 fields in line 5, saw 3\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Load the GBIF data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m dwnld_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/workspaces/data/data_download/gbi_data/0055584-251009101135966.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Convert to GeoDataFrame\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Check results\u001b[39;00m\n\u001b[32m      7\u001b[39m gbif_gdf.total_bounds\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 2 fields in line 5, saw 3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Load the GBIF data\n",
        "dwnld_df = pd.read_csv('/workspaces/data/data_download/gbi_data/0055584-251009101135966.csv')\n",
        "# Convert to GeoDataFrame\n",
        "\n",
        "# Check results\n",
        "gbif_gdf.total_bounds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91c8f771-29c1-4deb-acd2-ce0cba5800c5",
      "metadata": {},
      "source": [
        "# STEP -1: Wrap up\n",
        "\n",
        "Don’t forget to store your variables so you can use them in other\n",
        "notebooks! Replace `var1` and `var2` with the variable you want to save,\n",
        "separated by spaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b4ed5221",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stored 'gdf2' (GeoDataFrame)\n",
            "Stored 'df2' (DataFrame)\n",
            "Stored 'project' (Project)\n"
          ]
        }
      ],
      "source": [
        "%store gdf2 df2 project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "483de54c-9287-4ec3-ba27-26382dae3c62",
      "metadata": {},
      "source": [
        "Finally, be sure to `Restart` and `Run all` to make sure your notebook\n",
        "works all the way through!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
